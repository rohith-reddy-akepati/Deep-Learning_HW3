{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff7e49-e8b6-4a03-8d37-60bd41de88ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992b68a-c3f2-4413-af84-80a6ae7b6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25cff7d-0ae8-4bc7-9919-485920ae1ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/rchandr/.local/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.61it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:55<00:00, 286.86it/s]\n",
      "INFO:__main__:Epoch 1/5, Train Loss: 5.9499, WER Score: 14.2205, Precision: 0.1986, Recall: 0.7467, F1 Score: 0.2289\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:53<00:00, 298.14it/s]\n",
      "INFO:__main__:Epoch 2/5, Train Loss: 5.4005, WER Score: 5.6305, Precision: 0.4667, Recall: 0.6537, F1 Score: 0.4650\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:52<00:00, 302.57it/s]\n",
      "INFO:__main__:Epoch 3/5, Train Loss: 4.8369, WER Score: 3.0083, Precision: 0.5819, Recall: 0.6590, F1 Score: 0.5683\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.61it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:52<00:00, 303.70it/s]\n",
      "INFO:__main__:Epoch 4/5, Train Loss: 4.3375, WER Score: 1.7486, Precision: 0.6367, Recall: 0.6860, F1 Score: 0.6258\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:52<00:00, 304.03it/s]\n",
      "INFO:__main__:Epoch 5/5, Train Loss: 3.9897, WER Score: 1.6763, Precision: 0.6479, Recall: 0.6801, F1 Score: 0.6323\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging for detailed output\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Determine device for computation: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_data_file(path):\n",
    "    \"\"\"\n",
    "    Load and parse the dataset from a JSON file.\n",
    "    Extract contexts, questions, and answers from the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        raise\n",
    "\n",
    "    contexts, questions, answers = [], [], []\n",
    "    num_questions, num_possible, num_impossible = 0, 0, 0\n",
    "\n",
    "    # Extract data from the nested structure\n",
    "    for group in raw_data[\"data\"]:\n",
    "        for paragraph in group[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                num_questions += 1\n",
    "                if \"is_impossible\" in qa and qa[\"is_impossible\"]:\n",
    "                    num_impossible += 1\n",
    "                else:\n",
    "                    num_possible += 1\n",
    "                for answer in qa.get(\"answers\", []):\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return num_questions, num_possible, num_impossible, contexts, questions, answers\n",
    "\n",
    "# Load the training and validation datasets\n",
    "try:\n",
    "    num_train_questions, num_train_possible, num_train_impossible, train_contexts, train_questions, train_answers = load_data_file(\"spoken_train-v1.1.json\")\n",
    "    num_valid_questions, num_valid_possible, num_valid_impossible, valid_contexts, valid_questions, valid_answers = load_data_file(\"spoken_test-v1.1.json\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate and add end positions for each answer\n",
    "def add_answer_end_positions(answers):\n",
    "    \"\"\"\n",
    "    Calculate the end position of each answer based on its start position and length.\n",
    "    Add this information to the answer dictionary.\n",
    "    \"\"\"\n",
    "    for answer in answers:\n",
    "        answer_text = answer.get(\"text\", \"\").lower()\n",
    "        answer_start = answer.get(\"answer_start\", -1)\n",
    "        answer[\"answer_end\"] = answer_start + len(answer_text)\n",
    "\n",
    "# Add end positions to training and validation datasets\n",
    "add_answer_end_positions(train_answers)\n",
    "add_answer_end_positions(valid_answers)\n",
    "\n",
    "# Tokenizer and model configuration\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Tokenize the training and validation datasets\n",
    "train_encodings = tokenizer(train_questions, train_contexts, max_length=MAX_LENGTH, padding=True, truncation=True)\n",
    "valid_encodings = tokenizer(valid_questions, valid_contexts, max_length=MAX_LENGTH, padding=True, truncation=True)\n",
    "\n",
    "# Custom Dataset class to handle data preparation for PyTorch\n",
    "class QADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class to manage tokenized inputs and corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, answers):\n",
    "        self.encodings = encodings\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare tokenized inputs and corresponding answer positions\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"start_positions\"] = torch.tensor(self.answers[idx].get(\"answer_start\", -1))\n",
    "        item[\"end_positions\"] = torch.tensor(self.answers[idx].get(\"answer_end\", -1))\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = QADataset(train_encodings, train_answers)\n",
    "valid_dataset = QADataset(valid_encodings, valid_answers)\n",
    "\n",
    "# Initialize DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Load the pre-trained DistilBERT model for question answering\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(qa_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, dataloader, optimizer):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch using the given DataLoader and optimizer.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Return the average loss for the epoch\n",
    "\n",
    "# Function to evaluate the model on a validation dataset\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute the Word Error Rate (WER) and F1 score on the validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wer_list = []\n",
    "    all_true_answers = []\n",
    "    all_pred_answers = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_true = batch[\"start_positions\"].to(device)\n",
    "        end_true = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Predict start and end positions\n",
    "        start_pred = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_pred = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Decode predictions and true answers\n",
    "        for i in range(len(start_true)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i] + 1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][start_true[i]:end_true[i] + 1])\n",
    "            if true_answer.strip():\n",
    "                wer = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_list.append(wer)\n",
    "                all_true_answers.append(true_answer)\n",
    "                all_pred_answers.append(pred_answer)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    true_labels = [answer.split() for answer in all_true_answers]\n",
    "    pred_labels = [answer.split() for answer in all_pred_answers]\n",
    "    precision, recall, f1 = calculate_f1(true_labels, pred_labels)\n",
    "\n",
    "    # Return the average WER and F1 score across all samples\n",
    "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0.0\n",
    "    return avg_wer, precision, recall, f1\n",
    "\n",
    "# Helper function to calculate F1 score\n",
    "def calculate_f1(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for the given true and predicted labels.\n",
    "    \"\"\"\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        true_set = set(true)\n",
    "        pred_set = set(pred)\n",
    "        common = true_set.intersection(pred_set)\n",
    "        precision = len(common) / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        recall = len(common) / len(true_set) if len(true_set) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Training loop with early stopping\n",
    "EPOCHS = 5\n",
    "best_wer = float(\"inf\")\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_one_epoch(qa_model, train_loader, optimizer)\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    wer_score, precision, recall, f1 = evaluate_model(qa_model, valid_loader)\n",
    "    logger.info(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, WER Score: {wer_score:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Early stopping based on WER\n",
    "    if wer_score < best_wer:\n",
    "        best_wer = wer_score\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e431216-3e78-42fe-bbbc-d583ece62cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d49b8c-69ab-4367-b9a9-b6edb3fa3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tuned(model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291dd371-253b-4cd1-a5cc-688c960ab182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.67it/s]\n",
      "INFO:__main__:Epoch 1/5, Train Loss: 1.9182, WER Score: 1.8572, Precision: 0.6209, Recall: 0.6815, F1 Score: 0.6077\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.79it/s]\n",
      "INFO:__main__:Epoch 2/5, Train Loss: 1.0386, WER Score: 2.1329, Precision: 0.6312, Recall: 0.6892, F1 Score: 0.6149\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.24it/s]\n",
      "INFO:__main__:Epoch 3/5, Train Loss: 0.5879, WER Score: 2.1117, Precision: 0.6253, Recall: 0.6841, F1 Score: 0.6118\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.22it/s]\n",
      "INFO:__main__:Epoch 4/5, Train Loss: 0.3328, WER Score: 1.8963, Precision: 0.6342, Recall: 0.6874, F1 Score: 0.6177\n",
      "INFO:__main__:Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging for detailed output\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Determine device for computation: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_data_file(path):\n",
    "    \"\"\"\n",
    "    Load and parse the dataset from a JSON file.\n",
    "    Extract contexts, questions, and answers from the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        raise\n",
    "\n",
    "    contexts, questions, answers = [], [], []\n",
    "    num_questions, num_possible, num_impossible = 0, 0, 0\n",
    "\n",
    "    # Extract data from the nested structure\n",
    "    for group in raw_data[\"data\"]:\n",
    "        for paragraph in group[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                num_questions += 1\n",
    "                if \"is_impossible\" in qa and qa[\"is_impossible\"]:\n",
    "                    num_impossible += 1\n",
    "                else:\n",
    "                    num_possible += 1\n",
    "                for answer in qa.get(\"answers\", []):\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return num_questions, num_possible, num_impossible, contexts, questions, answers\n",
    "\n",
    "# Load the training and validation datasets\n",
    "try:\n",
    "    num_train_questions, num_train_possible, num_train_impossible, train_contexts, train_questions, train_answers = load_data_file(\"spoken_train-v1.1.json\")\n",
    "    num_valid_questions, num_valid_possible, num_valid_impossible, valid_contexts, valid_questions, valid_answers = load_data_file(\"spoken_test-v1.1.json\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate and add end positions for each answer\n",
    "def add_answer_end_positions(answers):\n",
    "    \"\"\"\n",
    "    Calculate the end position of each answer based on its start position and length.\n",
    "    Add this information to the answer dictionary.\n",
    "    \"\"\"\n",
    "    for answer in answers:\n",
    "        answer_text = answer.get(\"text\", \"\").lower()\n",
    "        answer_start = answer.get(\"answer_start\", -1)\n",
    "        answer[\"answer_end\"] = answer_start + len(answer_text)\n",
    "\n",
    "# Add end positions to training and validation datasets\n",
    "add_answer_end_positions(train_answers)\n",
    "add_answer_end_positions(valid_answers)\n",
    "\n",
    "# Tokenizer and model configuration\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Preprocessing function to handle offset mappings\n",
    "def preprocess_data(questions, contexts, answers, tokenizer, max_length=MAX_LENGTH):\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_char = answer['answer_start']\n",
    "        end_char = answer['answer_end']\n",
    "        offsets = encodings['offset_mapping'][i]\n",
    "        start_token, end_token = 0, 0\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    encodings.update({\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    })\n",
    "    return encodings\n",
    "\n",
    "# Preprocess the training and validation datasets\n",
    "train_encodings = preprocess_data(train_questions, train_contexts, train_answers, tokenizer)\n",
    "valid_encodings = preprocess_data(valid_questions, valid_contexts, valid_answers, tokenizer)\n",
    "\n",
    "# Custom Dataset class to handle data preparation for PyTorch\n",
    "class QADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class to manage tokenized inputs and corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, answers):\n",
    "        self.encodings = encodings\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare tokenized inputs and corresponding answer positions\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['start_positions'] = torch.tensor(self.encodings['start_positions'][idx])\n",
    "        item['end_positions'] = torch.tensor(self.encodings['end_positions'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = QADataset(train_encodings, train_answers)\n",
    "valid_dataset = QADataset(valid_encodings, valid_answers)\n",
    "\n",
    "# Initialize DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Load the pre-trained DistilBERT model for question answering\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(qa_model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch using the given DataLoader, optimizer, and scheduler.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Return the average loss for the epoch\n",
    "\n",
    "# Function to evaluate the model on a validation dataset\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute the Word Error Rate (WER) and F1 score on the validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wer_list = []\n",
    "    all_true_answers = []\n",
    "    all_pred_answers = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_true = batch[\"start_positions\"].to(device)\n",
    "        end_true = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Predict start and end positions\n",
    "        start_pred = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_pred = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Decode predictions and true answers\n",
    "        for i in range(len(start_true)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i] + 1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][start_true[i]:end_true[i] + 1])\n",
    "            if true_answer.strip():\n",
    "                wer = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_list.append(wer)\n",
    "                all_true_answers.append(true_answer)\n",
    "                all_pred_answers.append(pred_answer)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    true_labels = [answer.split() for answer in all_true_answers]\n",
    "    pred_labels = [answer.split() for answer in all_pred_answers]\n",
    "    precision, recall, f1 = calculate_f1(true_labels, pred_labels)\n",
    "\n",
    "    # Return the average WER and F1 score across all samples\n",
    "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0.0\n",
    "    return avg_wer, precision, recall, f1\n",
    "\n",
    "# Helper function to calculate F1 score\n",
    "def calculate_f1(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for the given true and predicted labels.\n",
    "    \"\"\"\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        true_set = set(true)\n",
    "        pred_set = set(pred)\n",
    "        common = true_set.intersection(pred_set)\n",
    "        precision = len(common) / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        recall = len(common) / len(true_set) if len(true_set) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Training loop with early stopping\n",
    "EPOCHS = 5\n",
    "best_wer = float(\"inf\")\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_one_epoch(qa_model, train_loader, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    wer_score, precision, recall, f1 = evaluate_model(qa_model, valid_loader)\n",
    "    logger.info(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, WER Score: {wer_score:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Early stopping based on WER\n",
    "    if wer_score < best_wer:\n",
    "        best_wer = wer_score\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89505a80-b329-4f56-897a-65619dd1b1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.49it/s]\n",
      "INFO:__main__:Epoch 1/5, Train Loss: 1.9238, WER Score: 2.3665, Precision: 0.6134, Recall: 0.6887, F1 Score: 0.6032\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.50it/s]\n",
      "INFO:__main__:Epoch 2/5, Train Loss: 1.0523, WER Score: 1.8325, Precision: 0.6344, Recall: 0.6887, F1 Score: 0.6187\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 291.97it/s]\n",
      "INFO:__main__:Epoch 3/5, Train Loss: 0.5978, WER Score: 1.8492, Precision: 0.6370, Recall: 0.6851, F1 Score: 0.6217\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.54it/s]\n",
      "INFO:__main__:Epoch 4/5, Train Loss: 0.3436, WER Score: 1.8043, Precision: 0.6238, Recall: 0.6892, F1 Score: 0.6144\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 292.06it/s]\n",
      "INFO:__main__:Epoch 5/5, Train Loss: 0.2052, WER Score: 1.8923, Precision: 0.6242, Recall: 0.6929, F1 Score: 0.6152\n"
     ]
    }
   ],
   "source": [
    "#pre processed(model3)\n",
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging for detailed output\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Determine device for computation: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_data_file(path):\n",
    "    \"\"\"\n",
    "    Load and parse the dataset from a JSON file.\n",
    "    Extract contexts, questions, and answers from the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        raise\n",
    "\n",
    "    contexts, questions, answers = [], [], []\n",
    "    num_questions, num_possible, num_impossible = 0, 0, 0\n",
    "\n",
    "    # Extract data from the nested structure\n",
    "    for group in raw_data[\"data\"]:\n",
    "        for paragraph in group[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                num_questions += 1\n",
    "                if \"is_impossible\" in qa and qa[\"is_impossible\"]:\n",
    "                    num_impossible += 1\n",
    "                else:\n",
    "                    num_possible += 1\n",
    "                for answer in qa.get(\"answers\", []):\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return num_questions, num_possible, num_impossible, contexts, questions, answers\n",
    "\n",
    "# Load the training and validation datasets\n",
    "try:\n",
    "    num_train_questions, num_train_possible, num_train_impossible, train_contexts, train_questions, train_answers = load_data_file(\"spoken_train-v1.1.json\")\n",
    "    num_valid_questions, num_valid_possible, num_valid_impossible, valid_contexts, valid_questions, valid_answers = load_data_file(\"spoken_test-v1.1.json\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate and add end positions for each answer\n",
    "def add_answer_end_positions(answers):\n",
    "    \"\"\"\n",
    "    Calculate the end position of each answer based on its start position and length.\n",
    "    Add this information to the answer dictionary.\n",
    "    \"\"\"\n",
    "    for answer in answers:\n",
    "        answer_text = answer.get(\"text\", \"\").lower()\n",
    "        answer_start = answer.get(\"answer_start\", -1)\n",
    "        answer[\"answer_end\"] = answer_start + len(answer_text)\n",
    "\n",
    "# Add end positions to training and validation datasets\n",
    "add_answer_end_positions(train_answers)\n",
    "add_answer_end_positions(valid_answers)\n",
    "\n",
    "# Tokenizer and model configuration\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Preprocessing function to handle offset mappings\n",
    "def preprocess_data(questions, contexts, answers, tokenizer, max_length=MAX_LENGTH):\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_char = answer['answer_start']\n",
    "        end_char = answer['answer_end']\n",
    "        offsets = encodings['offset_mapping'][i]\n",
    "        start_token, end_token = 0, 0\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    encodings.update({\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    })\n",
    "    return encodings\n",
    "\n",
    "# Preprocess the training and validation datasets\n",
    "train_encodings = preprocess_data(train_questions, train_contexts, train_answers, tokenizer)\n",
    "valid_encodings = preprocess_data(valid_questions, valid_contexts, valid_answers, tokenizer)\n",
    "\n",
    "# Custom Dataset class to handle data preparation for PyTorch\n",
    "class QADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class to manage tokenized inputs and corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, answers):\n",
    "        self.encodings = encodings\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare tokenized inputs and corresponding answer positions\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['start_positions'] = torch.tensor(self.encodings['start_positions'][idx])\n",
    "        item['end_positions'] = torch.tensor(self.encodings['end_positions'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = QADataset(train_encodings, train_answers)\n",
    "valid_dataset = QADataset(valid_encodings, valid_answers)\n",
    "\n",
    "# Initialize DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Load the pre-trained DistilBERT model for question answering\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(qa_model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch using the given DataLoader, optimizer, and scheduler.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Return the average loss for the epoch\n",
    "\n",
    "# Function to evaluate the model on a validation dataset\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute the Word Error Rate (WER), Precision, Recall, and F1 score on the validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wer_list = []\n",
    "    all_true_answers = []\n",
    "    all_pred_answers = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_true = batch[\"start_positions\"].to(device)\n",
    "        end_true = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Predict start and end positions\n",
    "        start_pred = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_pred = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Decode predictions and true answers\n",
    "        for i in range(len(start_true)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i] + 1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][start_true[i]:end_true[i] + 1])\n",
    "            if true_answer.strip():\n",
    "                wer = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_list.append(wer)\n",
    "                all_true_answers.append(true_answer)\n",
    "                all_pred_answers.append(pred_answer)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    true_labels = [answer.split() for answer in all_true_answers]\n",
    "    pred_labels = [answer.split() for answer in all_pred_answers]\n",
    "    precision, recall, f1 = calculate_f1(true_labels, pred_labels)\n",
    "\n",
    "    # Return the average WER and F1 score across all samples\n",
    "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0.0\n",
    "    return avg_wer, precision, recall, f1\n",
    "\n",
    "# Helper function to calculate F1 score\n",
    "def calculate_f1(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for the given true and predicted labels.\n",
    "    \"\"\"\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        true_set = set(true)\n",
    "        pred_set = set(pred)\n",
    "        common = true_set.intersection(pred_set)\n",
    "        precision = len(common) / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        recall = len(common) / len(true_set) if len(true_set) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Training loop with early stopping\n",
    "EPOCHS = 5\n",
    "best_wer = float(\"inf\")\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_one_epoch(qa_model, train_loader, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    wer_score, precision, recall, f1 = evaluate_model(qa_model, valid_loader)\n",
    "    logger.info(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, WER Score: {wer_score:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Early stopping based on WER\n",
    "    if wer_score < best_wer:\n",
    "        best_wer = wer_score\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c603694-6134-4729-b279-90790ddb01eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error loading data: not enough values to unpack (expected 6, got 3)\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.62it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 291.81it/s]\n",
      "INFO:__main__:Epoch 1/5, Train Loss: 2.3039, WER Score: 1.7629, Precision: 0.5646, Recall: 0.6015, F1 Score: 0.5393\n",
      "Training: 100%|██████████| 2320/2320 [02:28<00:00, 15.61it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [00:54<00:00, 291.86it/s]\n",
      "INFO:__main__:Epoch 2/5, Train Loss: 1.3667, WER Score: 1.8195, Precision: 0.5859, Recall: 0.6299, F1 Score: 0.5641\n",
      "Training:   1%|          | 27/2320 [00:01<02:26, 15.64it/s]"
     ]
    }
   ],
   "source": [
    "#post Processed(model4)\n",
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging for detailed output\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Determine device for computation: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_data_file(path):\n",
    "    # Read and parse the JSON file\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    # Initialize lists to hold contexts, questions, and answers\n",
    "    contexts, questions, answers = [], [], []\n",
    "\n",
    "    # Iterate through the dataset structure to extract the required fields\n",
    "    for group in raw_data[\"data\"]:\n",
    "        for paragraph in group[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"].lower()\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"].lower()\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    # Add context, question, and answer to respective lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n",
    "    \"\"\"\n",
    "    Load and parse the dataset from a JSON file.\n",
    "    Extract contexts, questions, and answers from the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {path}\")\n",
    "        raise\n",
    "\n",
    "    contexts, questions, answers = [], [], []\n",
    "    num_questions, num_possible, num_impossible = 0, 0, 0\n",
    "\n",
    "    # Extract data from the nested structure\n",
    "    for group in raw_data[\"data\"]:\n",
    "        for paragraph in group[\"paragraphs\"]:\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                num_questions += 1\n",
    "                if \"is_impossible\" in qa and qa[\"is_impossible\"]:\n",
    "                    num_impossible += 1\n",
    "                else:\n",
    "                    num_possible += 1\n",
    "                for answer in qa.get(\"answers\", []):\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return num_questions, num_possible, num_impossible, contexts, questions, answers\n",
    "\n",
    "# Load the training and validation datasets\n",
    "try:\n",
    "    num_train_questions, num_train_possible, num_train_impossible, train_contexts, train_questions, train_answers = load_data_file(\"spoken_train-v1.1.json\")\n",
    "    num_valid_questions, num_valid_possible, num_valid_impossible, valid_contexts, valid_questions, valid_answers = load_data_file(\"spoken_test-v1.1.json\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate and add end positions for each answer\n",
    "def add_answer_end_positions(answers):\n",
    "    for answer in answers:\n",
    "        # Convert the answer text to lowercase for consistency\n",
    "        answer[\"text\"] = answer[\"text\"].lower()\n",
    "\n",
    "        # Calculate the end position of the answer in the context\n",
    "        answer[\"answer_end\"] = answer[\"answer_start\"] + len(answer[\"text\"])\n",
    "    \"\"\"\n",
    "    Calculate the end position of each answer based on its start position and length.\n",
    "    Add this information to the answer dictionary.\n",
    "    \"\"\"\n",
    "    for answer in answers:\n",
    "        answer_text = answer.get(\"text\", \"\").lower()\n",
    "        answer_start = answer.get(\"answer_start\", -1)\n",
    "        answer[\"answer_end\"] = answer_start + len(answer_text)\n",
    "\n",
    "# Add end positions to training and validation datasets\n",
    "add_answer_end_positions(train_answers)\n",
    "add_answer_end_positions(valid_answers)\n",
    "add_answer_end_positions(valid_answers)\n",
    "\n",
    "# Tokenizer and model configuration\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Preprocessing function to handle offset mappings\n",
    "def preprocess_data(contexts, questions, answers, tokenizer, max_length=MAX_LENGTH):\n",
    "    # Tokenize the questions and contexts together\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    # Initialize lists to store the start and end positions in tokenized data\n",
    "    start_positions, end_positions = [], []\n",
    "\n",
    "    # Align answer positions with tokenized inputs using offset mapping\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_char = answer[\"answer_start\"]  # Character-level start position\n",
    "        end_char = answer[\"answer_end\"]  # Character-level end position\n",
    "        offsets = encodings[\"offset_mapping\"][i]  # Token offsets for the current input\n",
    "\n",
    "        # Default to start and end positions at 0 if alignment fails\n",
    "        start_token, end_token = 0, 0\n",
    "\n",
    "        # Match character positions to token positions\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:  # Start position is within the token span\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:  # End position is within the token span\n",
    "                end_token = idx\n",
    "\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    # Add start and end positions to the tokenized encodings\n",
    "    encodings.update({\n",
    "        \"start_positions\": start_positions,\n",
    "        \"end_positions\": end_positions,\n",
    "    })\n",
    "\n",
    "    return encodings\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_char = answer['answer_start']\n",
    "        end_char = answer['answer_end']\n",
    "        offsets = encodings['offset_mapping'][i]\n",
    "        start_token, end_token = 0, 0\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    encodings.update({\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    })\n",
    "    return encodings\n",
    "\n",
    "# Preprocess the training and validation datasets\n",
    "train_encodings = preprocess_data(train_questions, train_contexts, train_answers, tokenizer)\n",
    "valid_encodings = preprocess_data(valid_questions, valid_contexts, valid_answers, tokenizer)\n",
    "\n",
    "# Custom Dataset class to handle data preparation for PyTorch\n",
    "class QADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class to manage tokenized inputs and corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings, answers):\n",
    "        self.encodings = encodings\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Prepare tokenized inputs and corresponding answer positions\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['start_positions'] = torch.tensor(self.encodings['start_positions'][idx])\n",
    "        item['end_positions'] = torch.tensor(self.encodings['end_positions'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = QADataset(train_encodings, train_answers)\n",
    "valid_dataset = QADataset(valid_encodings, valid_answers)\n",
    "\n",
    "# Initialize DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Load the pre-trained DistilBERT model for question answering\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(qa_model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch using the given DataLoader, optimizer, and scheduler.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move inputs and labels to the device (GPU or CPU)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass and loss computation\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Average loss for the epoch\n",
    "    \"\"\"\n",
    "    Train the model for one epoch using the given DataLoader, optimizer, and scheduler.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)  # Return the average loss for the epoch\n",
    "\n",
    "# Function to evaluate the model on a validation dataset\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute the Word Error Rate (WER), Precision, Recall, and F1 score on the validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wer_list = []\n",
    "    all_true_answers = []\n",
    "    all_pred_answers = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        # Move inputs to the device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_true = batch[\"start_positions\"].to(device)\n",
    "        end_true = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        # Forward pass without gradient computation\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get predicted start and end positions\n",
    "        start_pred = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_pred = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Decode predictions and true answers\n",
    "        for i in range(len(start_true)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i] + 1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][start_true[i]:end_true[i] + 1])\n",
    "            if true_answer.strip():  # Avoid empty true answers\n",
    "                wer = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_list.append(wer)\n",
    "                all_true_answers.append(true_answer)\n",
    "                all_pred_answers.append(pred_answer)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    true_labels = [answer.split() for answer in all_true_answers]\n",
    "    pred_labels = [answer.split() for answer in all_pred_answers]\n",
    "    precision, recall, f1 = calculate_f1(true_labels, pred_labels)\n",
    "\n",
    "    # Return the average WER and F1 score across all samples\n",
    "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0.0\n",
    "    return avg_wer, precision, recall, f1\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute the Word Error Rate (WER), Precision, Recall, and F1 score on the validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    wer_list = []\n",
    "    all_true_answers = []\n",
    "    all_pred_answers = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        # Move data to the appropriate device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_true = batch[\"start_positions\"].to(device)\n",
    "        end_true = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Predict start and end positions\n",
    "        start_pred = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_pred = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Decode predictions and true answers\n",
    "        for i in range(len(start_true)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_pred[i]:end_pred[i] + 1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][start_true[i]:end_true[i] + 1])\n",
    "            if true_answer.strip():\n",
    "                wer = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_list.append(wer)\n",
    "                all_true_answers.append(true_answer)\n",
    "                all_pred_answers.append(pred_answer)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    true_labels = [answer.split() for answer in all_true_answers]\n",
    "    pred_labels = [answer.split() for answer in all_pred_answers]\n",
    "    precision, recall, f1 = calculate_f1(true_labels, pred_labels)\n",
    "\n",
    "    # Return the average WER and F1 score across all samples\n",
    "    avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0.0\n",
    "    return avg_wer, precision, recall, f1\n",
    "\n",
    "# Helper function to calculate F1 score\n",
    "def calculate_f1(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for the given true and predicted labels.\n",
    "    \"\"\"\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        true_set = set(true)\n",
    "        pred_set = set(pred)\n",
    "        common = true_set.intersection(pred_set)\n",
    "        precision = len(common) / len(pred_set) if len(pred_set) > 0 else 0\n",
    "        recall = len(common) / len(true_set) if len(true_set) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Training loop with early stopping\n",
    "EPOCHS = 5\n",
    "best_wer = float(\"inf\")\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_one_epoch(qa_model, train_loader, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    wer_score, precision, recall, f1 = evaluate_model(qa_model, valid_loader)\n",
    "    logger.info(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, WER Score: {wer_score:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Early stopping based on WER\n",
    "    if wer_score < best_wer:\n",
    "        best_wer = wer_score\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            logger.info(\"Early stopping triggered!\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
